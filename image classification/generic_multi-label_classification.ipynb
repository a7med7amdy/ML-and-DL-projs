{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "torch.set_printoptions(linewidth=120)\n",
    "import skimage.io as io\n",
    "import cv2 as cv2\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(batch_size,path):\n",
    "    data_dir = path\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(100),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(100),\n",
    "            transforms.CenterCrop(100),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "         'test': transforms.Compose([\n",
    "            transforms.Resize(100),\n",
    "            transforms.CenterCrop(100),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "\n",
    "    folders=os.listdir(os.path.join(data_dir, 'train'))\n",
    "    data_set = {x: torchvision.datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                  for x in ['train', 'val','test']}\n",
    "    train_loader = {x: torch.utils.data.DataLoader(data_set[x], batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val','test']}\n",
    "    return folders,data_set,train_loader,device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class focal loss to calculate the loss depending on the hard examples\n",
    "#focal loss class is for multi-label classification\n",
    "from torch.autograd import Variable\n",
    "def one_hot(index, classes,device):\n",
    "    size = index.size() + (classes,)\n",
    "    view = index.size() + (1,)\n",
    "\n",
    "    mask = torch.Tensor(*size).fill_(0)\n",
    "    mask=mask.to(device)\n",
    "    index = index.view(*view)\n",
    "    index=index.to(device)\n",
    "    ones = 1.\n",
    "\n",
    "    if isinstance(index, Variable):\n",
    "        ones = Variable(torch.Tensor(index.size()).fill_(1))\n",
    "        ones=ones.to(device)\n",
    "        mask = Variable(mask, volatile=index.volatile)\n",
    "\n",
    "    return mask.scatter_(1, index, ones)\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target,device):\n",
    "        y = one_hot(target, input.size(-1),device)\n",
    "        logit = F.softmax(input, dim=-1)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "\n",
    "        loss = -1 * y * torch.log(logit) # cross entropy\n",
    "        loss = loss * (1 - logit) ** self.gamma # focal loss\n",
    "\n",
    "        return loss.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet(n,device):\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    for param in resnet50.parameters():\n",
    "        param.require_grad = False\n",
    "\n",
    "    num_ftrs = resnet50.fc.in_features\n",
    "    resnet50.fc = nn.Linear(num_ftrs, n)\n",
    "    resnet50 = resnet50.to(device)\n",
    "    return resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model(resnet50,lr,n,device,train_loader,batch_size,epoch_num,tb):\n",
    "    optimizer= optim.Adam(resnet50.parameters(),lr=lr)\n",
    "    focal_loss_multilabel=FocalLoss()\n",
    "    for epoch in range (epoch_num):\n",
    "        total_loss=0\n",
    "        total_correct=0\n",
    "        #images, labels represent current batch\n",
    "        for images,labels in train_loader['train']:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "#             grid=torchvision.utils.make_grid(images)\n",
    "#             tb.add_images('images',grid, dataformats='CHW')\n",
    "#             tb.add_graph(resnet50,images)\n",
    "#             tb.close()\n",
    "            preds=resnet50(images)\n",
    "            loss=None\n",
    "            if(n>=3):\n",
    "                #if you want to calculate it using the normal cross entropy\n",
    "#                 loss = F.cross_entropy(preds,labels)\n",
    "                #if you want to calculate it using the focal loss\n",
    "                loss=focal_loss_multilabel.forward(preds,labels,device)\n",
    "            else:\n",
    "                #if you want to calculate it using the normal cross entropy\n",
    "#                 loss = F.binary_cross_entropy(preds,labels)\n",
    "                #if you want to calculate it using the focal loss\n",
    "                BCE_loss = F.binary_cross_entropy_with_logits(preds, labels, reduction='none')\n",
    "                pt = torch.exp(-BCE_loss) # prevents nans when probability 0\n",
    "                Focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "                loss= Focal_loss.mean()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss.item()\n",
    "            total_correct+=get_num_correct(preds,labels)\n",
    "            print (\"epoch: \",epoch,\" total_correct: \",total_correct,\" total_loss: \",total_loss)\n",
    "        tb.add_scalar('loss',total_loss,epoch)\n",
    "        tb.add_scalar('number correct',total_correct,epoch)\n",
    "        tb.add_scalar('accuracy',total_correct/(len(train_loader['train'])*batch_size),epoch)\n",
    "    return total_correct,total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_accuracy(total_correct,train_loader,batch_size):\n",
    "    print(\"train accuracy: \",total_correct/(len(train_loader['train'])*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(resnet50,device,train_loader,n,tb,batch_size):\n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    focal_loss_multilabel=FocalLoss()\n",
    "    for images,labels in train_loader['val']:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        preds=resnet50(images)\n",
    "        loss=None\n",
    "        \n",
    "        if(n>=3):\n",
    "            #if you want to calculate it using the normal cross entropy\n",
    "#                 loss = F.cross_entropy(preds,labels)\n",
    "            #if you want to calculate it using the focal loss\n",
    "            loss=focal_loss_multilabel.forward(preds,labels,device)\n",
    "        else:\n",
    "            #if you want to calculate it using the normal cross entropy\n",
    "#                 loss = F.binary_cross_entropy(preds,labels)\n",
    "            #if you want to calculate it using the focal loss\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(preds, labels, reduction='none')\n",
    "            pt = torch.exp(-BCE_loss) # prevents nans when probability 0\n",
    "            Focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "            loss= Focal_loss.mean()\n",
    "            \n",
    "        total_loss+=loss.item()\n",
    "        total_correct+=get_num_correct(preds,labels)\n",
    "        print (\"total_correct: \",total_correct,\" total_loss: \",total_loss)\n",
    "    tb.add_scalar('loss',total_loss,batch_size)\n",
    "    tb.add_scalar('number correct',total_correct,batch_size)\n",
    "    tb.add_scalar('accuracy',total_correct/(len(train_loader['train'])*batch_size),batch_size)\n",
    "    return total_correct,total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_validation_accuracy(total_correct,train_loader,batch_size):\n",
    "    print(\"validation accuracy: \",total_correct/(len(train_loader['val'])*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def testing(resnet50,device,train_loader,n):\n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    focal_loss_multilabel=FocalLoss()\n",
    "    for images,labels in train_loader['test']:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        preds=resnet50(images)\n",
    "        loss=None\n",
    "        if(n>=3):\n",
    "            #if you want to calculate it using the normal cross entropy\n",
    "#                 loss = F.cross_entropy(preds,labels)\n",
    "            #if you want to calculate it using the focal loss\n",
    "            loss=focal_loss_multilabel.forward(preds,labels,device)\n",
    "        else:\n",
    "            #if you want to calculate it using the normal cross entropy\n",
    "#                 loss = F.binary_cross_entropy(preds,labels)\n",
    "            #if you want to calculate it using the focal loss\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(preds, labels, reduction='none')\n",
    "            pt = torch.exp(-BCE_loss) # prevents nans when probability 0\n",
    "            Focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "            loss= Focal_loss.mean()\n",
    "        total_loss+=loss.item()\n",
    "        total_correct+=get_num_correct(preds,labels)\n",
    "        print (\"total_correct: \",total_correct,\" total_loss: \",total_loss)\n",
    "    return total_correct,total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_testing_accuracy(total_correct,train_loader,batch_size):\n",
    "    print(\"testing_accuracy: \",total_correct/(len(train_loader['test'])*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "#     batch_size_list=[32,64,128]\n",
    "#     lr_list=[0.0001,0.00001,0.000001]\n",
    "#     epoch_num_list=[10,17,23]\n",
    "#     for batch_size in batch_size_list :\n",
    "#         for lr in lr_list :\n",
    "#             for epoch_num in epoch_num_list:\n",
    "                batch_size=64\n",
    "                lr=0.00001\n",
    "                epoch_num=23\n",
    "                folder,data_set,train_loader,device=prepare_data(batch_size,\"/home/ahmed/intern work/image classification/animal-image-datasetdog-cat-and-panda\")\n",
    "                print(len(folder))\n",
    "                print(\"no of data = \",len(train_loader['train'])*batch_size)\n",
    "                n=len(folder)\n",
    "                tb=SummaryWriter()\n",
    "                resnet50=get_resnet(n,device)\n",
    "                total_correct,total_loss=model(resnet50,lr,n,device,train_loader,batch_size,epoch_num,tb)\n",
    "                print_train_accuracy(total_correct,train_loader,batch_size)\n",
    "                total_correct,total_loss=validation(resnet50,device,train_loader,n,tb,batch_size)\n",
    "                print_validation_accuracy(total_correct,train_loader,batch_size)\n",
    "                total_correct,total_loss=testing(resnet50,device,train_loader,n)\n",
    "                print_testing_accuracy(total_correct,train_loader,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "3\n",
      "no of data =  2176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: volatile was removed (Variable.volatile is always False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  total_correct:  30  total_loss:  68.32234191894531\n",
      "epoch:  0  total_correct:  53  total_loss:  138.0527114868164\n",
      "epoch:  0  total_correct:  83  total_loss:  202.70592498779297\n",
      "epoch:  0  total_correct:  119  total_loss:  265.53893661499023\n",
      "epoch:  0  total_correct:  157  total_loss:  326.8213768005371\n",
      "epoch:  0  total_correct:  191  total_loss:  390.432315826416\n",
      "epoch:  0  total_correct:  221  total_loss:  453.9290657043457\n",
      "epoch:  0  total_correct:  259  total_loss:  515.063892364502\n",
      "epoch:  0  total_correct:  307  total_loss:  570.3730430603027\n",
      "epoch:  0  total_correct:  354  total_loss:  626.4813804626465\n",
      "epoch:  0  total_correct:  396  total_loss:  684.331356048584\n",
      "epoch:  0  total_correct:  443  total_loss:  736.4275093078613\n",
      "epoch:  0  total_correct:  492  total_loss:  788.6994590759277\n",
      "epoch:  0  total_correct:  539  total_loss:  841.132137298584\n",
      "epoch:  0  total_correct:  585  total_loss:  892.5668067932129\n",
      "epoch:  0  total_correct:  631  total_loss:  944.439037322998\n",
      "epoch:  0  total_correct:  680  total_loss:  995.4134559631348\n",
      "epoch:  0  total_correct:  728  total_loss:  1043.9939727783203\n",
      "epoch:  0  total_correct:  778  total_loss:  1089.590705871582\n",
      "epoch:  0  total_correct:  827  total_loss:  1135.0093955993652\n",
      "epoch:  0  total_correct:  880  total_loss:  1180.5141410827637\n",
      "epoch:  0  total_correct:  928  total_loss:  1228.3537940979004\n",
      "epoch:  0  total_correct:  986  total_loss:  1269.2487411499023\n",
      "epoch:  0  total_correct:  1044  total_loss:  1311.2342376708984\n",
      "epoch:  0  total_correct:  1096  total_loss:  1353.168197631836\n",
      "epoch:  0  total_correct:  1151  total_loss:  1393.966480255127\n",
      "epoch:  0  total_correct:  1204  total_loss:  1434.840663909912\n",
      "epoch:  0  total_correct:  1257  total_loss:  1475.7319450378418\n",
      "epoch:  0  total_correct:  1307  total_loss:  1517.454418182373\n",
      "epoch:  0  total_correct:  1360  total_loss:  1558.8618812561035\n",
      "epoch:  0  total_correct:  1411  total_loss:  1601.572910308838\n",
      "epoch:  0  total_correct:  1464  total_loss:  1641.6781578063965\n",
      "epoch:  0  total_correct:  1518  total_loss:  1679.1807823181152\n",
      "epoch:  0  total_correct:  1534  total_loss:  1690.6658935546875\n",
      "epoch:  1  total_correct:  52  total_loss:  38.8826904296875\n",
      "epoch:  1  total_correct:  107  total_loss:  73.49510192871094\n",
      "epoch:  1  total_correct:  164  total_loss:  105.27410507202148\n",
      "epoch:  1  total_correct:  222  total_loss:  140.37997817993164\n",
      "epoch:  1  total_correct:  280  total_loss:  172.07168197631836\n",
      "epoch:  1  total_correct:  337  total_loss:  201.78326988220215\n",
      "epoch:  1  total_correct:  395  total_loss:  232.70135116577148\n",
      "epoch:  1  total_correct:  448  total_loss:  266.2348327636719\n",
      "epoch:  1  total_correct:  507  total_loss:  296.88067626953125\n",
      "epoch:  1  total_correct:  558  total_loss:  330.58644104003906\n",
      "epoch:  1  total_correct:  615  total_loss:  361.2018070220947\n",
      "epoch:  1  total_correct:  676  total_loss:  387.2120666503906\n",
      "epoch:  1  total_correct:  736  total_loss:  414.11309242248535\n",
      "epoch:  1  total_correct:  792  total_loss:  442.83955574035645\n",
      "epoch:  1  total_correct:  850  total_loss:  470.4508247375488\n",
      "epoch:  1  total_correct:  904  total_loss:  500.0774116516113\n",
      "epoch:  1  total_correct:  959  total_loss:  527.7717895507812\n",
      "epoch:  1  total_correct:  1017  total_loss:  557.282958984375\n",
      "epoch:  1  total_correct:  1072  total_loss:  584.8475227355957\n",
      "epoch:  1  total_correct:  1128  total_loss:  611.2618713378906\n",
      "epoch:  1  total_correct:  1186  total_loss:  636.5779514312744\n",
      "epoch:  1  total_correct:  1247  total_loss:  661.5343494415283\n",
      "epoch:  1  total_correct:  1307  total_loss:  684.2567920684814\n",
      "epoch:  1  total_correct:  1369  total_loss:  706.9109973907471\n",
      "epoch:  1  total_correct:  1430  total_loss:  730.3739433288574\n",
      "epoch:  1  total_correct:  1491  total_loss:  753.6297454833984\n",
      "epoch:  1  total_correct:  1548  total_loss:  779.8658638000488\n",
      "epoch:  1  total_correct:  1609  total_loss:  803.4570846557617\n",
      "epoch:  1  total_correct:  1667  total_loss:  825.6995220184326\n",
      "epoch:  1  total_correct:  1726  total_loss:  847.5887641906738\n",
      "epoch:  1  total_correct:  1784  total_loss:  871.2908782958984\n",
      "epoch:  1  total_correct:  1841  total_loss:  895.7050323486328\n",
      "epoch:  1  total_correct:  1901  total_loss:  915.3294200897217\n",
      "epoch:  1  total_correct:  1917  total_loss:  925.3950710296631\n",
      "epoch:  2  total_correct:  61  total_loss:  19.515884399414062\n",
      "epoch:  2  total_correct:  119  total_loss:  42.271366119384766\n",
      "epoch:  2  total_correct:  177  total_loss:  63.55237579345703\n",
      "epoch:  2  total_correct:  238  total_loss:  81.39886283874512\n",
      "epoch:  2  total_correct:  293  total_loss:  101.13130378723145\n",
      "epoch:  2  total_correct:  357  total_loss:  118.48225593566895\n",
      "epoch:  2  total_correct:  416  total_loss:  137.9697265625\n",
      "epoch:  2  total_correct:  475  total_loss:  159.34662246704102\n",
      "epoch:  2  total_correct:  533  total_loss:  180.06241035461426\n",
      "epoch:  2  total_correct:  591  total_loss:  204.36281776428223\n",
      "epoch:  2  total_correct:  651  total_loss:  224.25181198120117\n",
      "epoch:  2  total_correct:  713  total_loss:  244.09873580932617\n",
      "epoch:  2  total_correct:  771  total_loss:  263.427303314209\n",
      "epoch:  2  total_correct:  832  total_loss:  279.9655570983887\n",
      "epoch:  2  total_correct:  893  total_loss:  296.5362033843994\n",
      "epoch:  2  total_correct:  951  total_loss:  317.19511222839355\n",
      "epoch:  2  total_correct:  1011  total_loss:  335.3084716796875\n",
      "epoch:  2  total_correct:  1069  total_loss:  352.84935760498047\n",
      "epoch:  2  total_correct:  1130  total_loss:  369.9517822265625\n",
      "epoch:  2  total_correct:  1191  total_loss:  387.01689529418945\n",
      "epoch:  2  total_correct:  1250  total_loss:  406.2543716430664\n",
      "epoch:  2  total_correct:  1311  total_loss:  420.3847942352295\n",
      "epoch:  2  total_correct:  1373  total_loss:  433.047176361084\n",
      "epoch:  2  total_correct:  1432  total_loss:  451.04136848449707\n",
      "epoch:  2  total_correct:  1492  total_loss:  468.48355865478516\n",
      "epoch:  2  total_correct:  1553  total_loss:  485.0511302947998\n",
      "epoch:  2  total_correct:  1610  total_loss:  501.357515335083\n",
      "epoch:  2  total_correct:  1668  total_loss:  518.6198635101318\n",
      "epoch:  2  total_correct:  1727  total_loss:  535.9152774810791\n",
      "epoch:  2  total_correct:  1786  total_loss:  551.8700561523438\n",
      "epoch:  2  total_correct:  1846  total_loss:  571.1934261322021\n",
      "epoch:  2  total_correct:  1907  total_loss:  586.6739301681519\n",
      "epoch:  2  total_correct:  1967  total_loss:  601.6037731170654\n",
      "epoch:  2  total_correct:  1985  total_loss:  606.0584030151367\n",
      "epoch:  3  total_correct:  61  total_loss:  16.048133850097656\n",
      "epoch:  3  total_correct:  120  total_loss:  32.087005615234375\n",
      "epoch:  3  total_correct:  182  total_loss:  45.06729316711426\n",
      "epoch:  3  total_correct:  244  total_loss:  58.47595405578613\n",
      "epoch:  3  total_correct:  300  total_loss:  77.54247665405273\n",
      "epoch:  3  total_correct:  360  total_loss:  90.97846508026123\n",
      "epoch:  3  total_correct:  423  total_loss:  102.84256362915039\n",
      "epoch:  3  total_correct:  486  total_loss:  113.6415023803711\n",
      "epoch:  3  total_correct:  544  total_loss:  131.59830856323242\n",
      "epoch:  3  total_correct:  602  total_loss:  146.79152297973633\n",
      "epoch:  3  total_correct:  663  total_loss:  157.61130332946777\n",
      "epoch:  3  total_correct:  723  total_loss:  172.05800342559814\n",
      "epoch:  3  total_correct:  782  total_loss:  188.63262844085693\n",
      "epoch:  3  total_correct:  841  total_loss:  203.83792686462402\n",
      "epoch:  3  total_correct:  900  total_loss:  216.939923286438\n",
      "epoch:  3  total_correct:  959  total_loss:  234.54223346710205\n",
      "epoch:  3  total_correct:  1016  total_loss:  249.33257389068604\n",
      "epoch:  3  total_correct:  1076  total_loss:  262.6459445953369\n",
      "epoch:  3  total_correct:  1135  total_loss:  276.69007682800293\n",
      "epoch:  3  total_correct:  1193  total_loss:  291.7958183288574\n",
      "epoch:  3  total_correct:  1253  total_loss:  306.25165367126465\n",
      "epoch:  3  total_correct:  1313  total_loss:  320.7714538574219\n",
      "epoch:  3  total_correct:  1370  total_loss:  338.2110595703125\n",
      "epoch:  3  total_correct:  1430  total_loss:  350.91362380981445\n",
      "epoch:  3  total_correct:  1489  total_loss:  363.44400787353516\n",
      "epoch:  3  total_correct:  1550  total_loss:  376.4027442932129\n",
      "epoch:  3  total_correct:  1609  total_loss:  387.9327163696289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3  total_correct:  1669  total_loss:  400.10960388183594\n",
      "epoch:  3  total_correct:  1728  total_loss:  413.2683849334717\n",
      "epoch:  3  total_correct:  1785  total_loss:  429.05384826660156\n",
      "epoch:  3  total_correct:  1841  total_loss:  445.2961730957031\n",
      "epoch:  3  total_correct:  1898  total_loss:  461.6506690979004\n",
      "epoch:  3  total_correct:  1955  total_loss:  479.9057807922363\n",
      "epoch:  3  total_correct:  1970  total_loss:  490.02149295806885\n",
      "epoch:  4  total_correct:  62  total_loss:  10.414356231689453\n",
      "epoch:  4  total_correct:  124  total_loss:  22.171344757080078\n",
      "epoch:  4  total_correct:  185  total_loss:  34.287240982055664\n",
      "epoch:  4  total_correct:  247  total_loss:  46.270562171936035\n",
      "epoch:  4  total_correct:  307  total_loss:  57.27195644378662\n",
      "epoch:  4  total_correct:  365  total_loss:  73.87461757659912\n",
      "epoch:  4  total_correct:  424  total_loss:  86.50844287872314\n",
      "epoch:  4  total_correct:  488  total_loss:  92.90542125701904\n",
      "epoch:  4  total_correct:  550  total_loss:  100.70439434051514\n",
      "epoch:  4  total_correct:  610  total_loss:  111.68532466888428\n",
      "epoch:  4  total_correct:  670  total_loss:  124.4968729019165\n",
      "epoch:  4  total_correct:  733  total_loss:  129.43735885620117\n",
      "epoch:  4  total_correct:  792  total_loss:  142.91135597229004\n",
      "epoch:  4  total_correct:  854  total_loss:  153.0326166152954\n",
      "epoch:  4  total_correct:  914  total_loss:  164.14456844329834\n",
      "epoch:  4  total_correct:  975  total_loss:  174.0739278793335\n",
      "epoch:  4  total_correct:  1036  total_loss:  183.94237232208252\n",
      "epoch:  4  total_correct:  1096  total_loss:  193.49771881103516\n",
      "epoch:  4  total_correct:  1156  total_loss:  206.46043968200684\n",
      "epoch:  4  total_correct:  1213  total_loss:  220.99201583862305\n",
      "epoch:  4  total_correct:  1273  total_loss:  230.03196048736572\n",
      "epoch:  4  total_correct:  1337  total_loss:  237.71714973449707\n",
      "epoch:  4  total_correct:  1398  total_loss:  246.34543132781982\n",
      "epoch:  4  total_correct:  1458  total_loss:  256.9162702560425\n",
      "epoch:  4  total_correct:  1517  total_loss:  270.5388822555542\n",
      "epoch:  4  total_correct:  1576  total_loss:  283.8548641204834\n",
      "epoch:  4  total_correct:  1638  total_loss:  294.2961673736572\n",
      "epoch:  4  total_correct:  1697  total_loss:  304.03167152404785\n",
      "epoch:  4  total_correct:  1758  total_loss:  312.3239212036133\n",
      "epoch:  4  total_correct:  1817  total_loss:  325.57493782043457\n",
      "epoch:  4  total_correct:  1878  total_loss:  336.61137294769287\n",
      "epoch:  4  total_correct:  1935  total_loss:  349.9712619781494\n",
      "epoch:  4  total_correct:  1992  total_loss:  366.9473762512207\n",
      "epoch:  4  total_correct:  2009  total_loss:  372.0271883010864\n",
      "epoch:  5  total_correct:  61  total_loss:  9.787242889404297\n",
      "epoch:  5  total_correct:  119  total_loss:  22.33203887939453\n",
      "epoch:  5  total_correct:  178  total_loss:  35.47718524932861\n",
      "epoch:  5  total_correct:  238  total_loss:  44.07677173614502\n",
      "epoch:  5  total_correct:  299  total_loss:  53.779093742370605\n",
      "epoch:  5  total_correct:  360  total_loss:  64.07617855072021\n",
      "epoch:  5  total_correct:  420  total_loss:  74.36243343353271\n",
      "epoch:  5  total_correct:  481  total_loss:  82.44705581665039\n",
      "epoch:  5  total_correct:  542  total_loss:  91.8276195526123\n",
      "epoch:  5  total_correct:  606  total_loss:  97.3866810798645\n",
      "epoch:  5  total_correct:  668  total_loss:  103.82663345336914\n",
      "epoch:  5  total_correct:  729  total_loss:  113.69316577911377\n",
      "epoch:  5  total_correct:  792  total_loss:  120.72006607055664\n",
      "epoch:  5  total_correct:  852  total_loss:  130.71252632141113\n",
      "epoch:  5  total_correct:  912  total_loss:  141.09093856811523\n",
      "epoch:  5  total_correct:  973  total_loss:  147.70923948287964\n",
      "epoch:  5  total_correct:  1033  total_loss:  157.3240294456482\n",
      "epoch:  5  total_correct:  1094  total_loss:  167.3714509010315\n",
      "epoch:  5  total_correct:  1157  total_loss:  174.49683332443237\n",
      "epoch:  5  total_correct:  1220  total_loss:  184.0998854637146\n",
      "epoch:  5  total_correct:  1280  total_loss:  194.5151972770691\n",
      "epoch:  5  total_correct:  1340  total_loss:  205.73426485061646\n",
      "epoch:  5  total_correct:  1400  total_loss:  216.99782419204712\n",
      "epoch:  5  total_correct:  1461  total_loss:  228.57695055007935\n",
      "epoch:  5  total_correct:  1518  total_loss:  245.45706033706665\n",
      "epoch:  5  total_correct:  1579  total_loss:  252.8664150238037\n",
      "epoch:  5  total_correct:  1640  total_loss:  263.09893798828125\n",
      "epoch:  5  total_correct:  1701  total_loss:  272.2818908691406\n",
      "epoch:  5  total_correct:  1764  total_loss:  278.26127338409424\n",
      "epoch:  5  total_correct:  1827  total_loss:  283.74239110946655\n",
      "epoch:  5  total_correct:  1885  total_loss:  295.269690990448\n",
      "epoch:  5  total_correct:  1948  total_loss:  301.54951763153076\n",
      "epoch:  5  total_correct:  2008  total_loss:  309.4746894836426\n",
      "epoch:  5  total_correct:  2024  total_loss:  316.33969163894653\n",
      "epoch:  6  total_correct:  64  total_loss:  6.086629867553711\n",
      "epoch:  6  total_correct:  126  total_loss:  15.544713973999023\n",
      "epoch:  6  total_correct:  189  total_loss:  22.71408224105835\n",
      "epoch:  6  total_correct:  251  total_loss:  29.983448028564453\n",
      "epoch:  6  total_correct:  315  total_loss:  35.49484634399414\n",
      "epoch:  6  total_correct:  375  total_loss:  42.92963457107544\n",
      "epoch:  6  total_correct:  438  total_loss:  48.64763116836548\n",
      "epoch:  6  total_correct:  500  total_loss:  57.44580125808716\n",
      "epoch:  6  total_correct:  560  total_loss:  68.84985208511353\n",
      "epoch:  6  total_correct:  622  total_loss:  79.57970952987671\n",
      "epoch:  6  total_correct:  684  total_loss:  88.20087766647339\n",
      "epoch:  6  total_correct:  745  total_loss:  98.43319654464722\n",
      "epoch:  6  total_correct:  805  total_loss:  111.37935876846313\n",
      "epoch:  6  total_correct:  864  total_loss:  122.35077142715454\n",
      "epoch:  6  total_correct:  927  total_loss:  130.4057478904724\n",
      "epoch:  6  total_correct:  989  total_loss:  138.8992600440979\n",
      "epoch:  6  total_correct:  1048  total_loss:  150.20600748062134\n",
      "epoch:  6  total_correct:  1109  total_loss:  157.94152879714966\n",
      "epoch:  6  total_correct:  1171  total_loss:  165.10234117507935\n",
      "epoch:  6  total_correct:  1232  total_loss:  173.78174543380737\n",
      "epoch:  6  total_correct:  1293  total_loss:  184.9245629310608\n",
      "epoch:  6  total_correct:  1356  total_loss:  190.14317083358765\n",
      "epoch:  6  total_correct:  1420  total_loss:  195.1339898109436\n",
      "epoch:  6  total_correct:  1483  total_loss:  202.17493152618408\n",
      "epoch:  6  total_correct:  1542  total_loss:  212.48487186431885\n",
      "epoch:  6  total_correct:  1601  total_loss:  227.00274181365967\n",
      "epoch:  6  total_correct:  1665  total_loss:  231.6222915649414\n",
      "epoch:  6  total_correct:  1724  total_loss:  245.60084533691406\n",
      "epoch:  6  total_correct:  1787  total_loss:  250.61081218719482\n",
      "epoch:  6  total_correct:  1850  total_loss:  258.59276151657104\n",
      "epoch:  6  total_correct:  1914  total_loss:  261.6082353591919\n",
      "epoch:  6  total_correct:  1976  total_loss:  270.3994426727295\n",
      "epoch:  6  total_correct:  2040  total_loss:  275.27773094177246\n",
      "epoch:  6  total_correct:  2059  total_loss:  276.62429881095886\n",
      "epoch:  7  total_correct:  61  total_loss:  7.799708843231201\n",
      "epoch:  7  total_correct:  121  total_loss:  18.115986347198486\n",
      "epoch:  7  total_correct:  183  total_loss:  25.01801633834839\n",
      "epoch:  7  total_correct:  243  total_loss:  35.98060846328735\n",
      "epoch:  7  total_correct:  306  total_loss:  42.98805093765259\n",
      "epoch:  7  total_correct:  368  total_loss:  50.91400671005249\n",
      "epoch:  7  total_correct:  432  total_loss:  54.7090060710907\n",
      "epoch:  7  total_correct:  492  total_loss:  62.988094091415405\n",
      "epoch:  7  total_correct:  555  total_loss:  67.79188513755798\n",
      "epoch:  7  total_correct:  615  total_loss:  77.20851302146912\n",
      "epoch:  7  total_correct:  678  total_loss:  82.06092572212219\n",
      "epoch:  7  total_correct:  738  total_loss:  90.63466191291809\n",
      "epoch:  7  total_correct:  801  total_loss:  94.78242325782776\n",
      "epoch:  7  total_correct:  865  total_loss:  98.39616560935974\n",
      "epoch:  7  total_correct:  928  total_loss:  104.17642188072205\n",
      "epoch:  7  total_correct:  989  total_loss:  111.70540356636047\n",
      "epoch:  7  total_correct:  1052  total_loss:  115.1510226726532\n",
      "epoch:  7  total_correct:  1111  total_loss:  123.01642775535583\n",
      "epoch:  7  total_correct:  1175  total_loss:  126.04145407676697\n",
      "epoch:  7  total_correct:  1238  total_loss:  130.24278283119202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7  total_correct:  1300  total_loss:  134.9877188205719\n",
      "epoch:  7  total_correct:  1362  total_loss:  145.59894013404846\n",
      "epoch:  7  total_correct:  1426  total_loss:  150.85679602622986\n",
      "epoch:  7  total_correct:  1487  total_loss:  158.02488112449646\n",
      "epoch:  7  total_correct:  1544  total_loss:  171.81602835655212\n",
      "epoch:  7  total_correct:  1605  total_loss:  177.9944303035736\n",
      "epoch:  7  total_correct:  1666  total_loss:  183.2606647014618\n",
      "epoch:  7  total_correct:  1727  total_loss:  192.5253827571869\n",
      "epoch:  7  total_correct:  1788  total_loss:  200.0685431957245\n",
      "epoch:  7  total_correct:  1851  total_loss:  205.11783957481384\n",
      "epoch:  7  total_correct:  1909  total_loss:  215.60123324394226\n",
      "epoch:  7  total_correct:  1970  total_loss:  223.12147784233093\n",
      "epoch:  7  total_correct:  2034  total_loss:  226.4083812236786\n",
      "epoch:  7  total_correct:  2050  total_loss:  229.77667140960693\n",
      "epoch:  8  total_correct:  63  total_loss:  4.183136940002441\n",
      "epoch:  8  total_correct:  127  total_loss:  7.0094990730285645\n",
      "epoch:  8  total_correct:  189  total_loss:  13.381995677947998\n",
      "epoch:  8  total_correct:  249  total_loss:  24.250537395477295\n",
      "epoch:  8  total_correct:  312  total_loss:  27.555431365966797\n",
      "epoch:  8  total_correct:  372  total_loss:  34.77318048477173\n",
      "epoch:  8  total_correct:  432  total_loss:  43.78189134597778\n",
      "epoch:  8  total_correct:  490  total_loss:  53.76918840408325\n",
      "epoch:  8  total_correct:  553  total_loss:  58.61578416824341\n",
      "epoch:  8  total_correct:  615  total_loss:  64.51115131378174\n",
      "epoch:  8  total_correct:  676  total_loss:  70.40705299377441\n",
      "epoch:  8  total_correct:  739  total_loss:  74.78275871276855\n",
      "epoch:  8  total_correct:  801  total_loss:  80.38530254364014\n",
      "epoch:  8  total_correct:  862  total_loss:  90.01588821411133\n",
      "epoch:  8  total_correct:  923  total_loss:  98.57844543457031\n",
      "epoch:  8  total_correct:  986  total_loss:  103.0815954208374\n",
      "epoch:  8  total_correct:  1049  total_loss:  110.03925561904907\n",
      "epoch:  8  total_correct:  1111  total_loss:  117.2213134765625\n",
      "epoch:  8  total_correct:  1172  total_loss:  124.99693965911865\n",
      "epoch:  8  total_correct:  1234  total_loss:  130.84755039215088\n",
      "epoch:  8  total_correct:  1297  total_loss:  135.0725917816162\n",
      "epoch:  8  total_correct:  1358  total_loss:  144.16863822937012\n",
      "epoch:  8  total_correct:  1422  total_loss:  148.04863619804382\n",
      "epoch:  8  total_correct:  1483  total_loss:  156.1829764842987\n",
      "epoch:  8  total_correct:  1545  total_loss:  162.51399397850037\n",
      "epoch:  8  total_correct:  1607  total_loss:  169.68591809272766\n",
      "epoch:  8  total_correct:  1670  total_loss:  173.35884547233582\n",
      "epoch:  8  total_correct:  1729  total_loss:  185.01813769340515\n",
      "epoch:  8  total_correct:  1793  total_loss:  187.08042764663696\n",
      "epoch:  8  total_correct:  1857  total_loss:  190.3119339942932\n",
      "epoch:  8  total_correct:  1918  total_loss:  201.56498956680298\n",
      "epoch:  8  total_correct:  1980  total_loss:  207.7209963798523\n",
      "epoch:  8  total_correct:  2042  total_loss:  213.2890591621399\n",
      "epoch:  8  total_correct:  2060  total_loss:  215.4088773727417\n",
      "epoch:  9  total_correct:  62  total_loss:  5.811623573303223\n",
      "epoch:  9  total_correct:  125  total_loss:  10.754117012023926\n",
      "epoch:  9  total_correct:  188  total_loss:  16.058754444122314\n",
      "epoch:  9  total_correct:  251  total_loss:  21.135305404663086\n",
      "epoch:  9  total_correct:  311  total_loss:  29.273900985717773\n",
      "epoch:  9  total_correct:  374  total_loss:  36.70840930938721\n",
      "epoch:  9  total_correct:  437  total_loss:  39.760056495666504\n",
      "epoch:  9  total_correct:  500  total_loss:  44.53852939605713\n",
      "epoch:  9  total_correct:  563  total_loss:  49.58773756027222\n",
      "epoch:  9  total_correct:  627  total_loss:  50.967997550964355\n",
      "epoch:  9  total_correct:  689  total_loss:  57.35815238952637\n",
      "epoch:  9  total_correct:  750  total_loss:  64.26573848724365\n",
      "epoch:  9  total_correct:  808  total_loss:  74.40713119506836\n",
      "epoch:  9  total_correct:  869  total_loss:  80.07123136520386\n",
      "epoch:  9  total_correct:  931  total_loss:  86.411048412323\n",
      "epoch:  9  total_correct:  994  total_loss:  91.09269952774048\n",
      "epoch:  9  total_correct:  1056  total_loss:  96.01150178909302\n",
      "epoch:  9  total_correct:  1119  total_loss:  99.17650580406189\n",
      "epoch:  9  total_correct:  1182  total_loss:  102.49091362953186\n",
      "epoch:  9  total_correct:  1243  total_loss:  110.20000386238098\n",
      "epoch:  9  total_correct:  1304  total_loss:  116.55508351325989\n",
      "epoch:  9  total_correct:  1367  total_loss:  120.37628221511841\n",
      "epoch:  9  total_correct:  1430  total_loss:  123.71125602722168\n",
      "epoch:  9  total_correct:  1493  total_loss:  127.52620077133179\n",
      "epoch:  9  total_correct:  1556  total_loss:  130.3725962638855\n",
      "epoch:  9  total_correct:  1618  total_loss:  135.6735873222351\n",
      "epoch:  9  total_correct:  1681  total_loss:  138.84828329086304\n",
      "epoch:  9  total_correct:  1742  total_loss:  148.05673837661743\n",
      "epoch:  9  total_correct:  1801  total_loss:  158.75757551193237\n",
      "epoch:  9  total_correct:  1863  total_loss:  164.43025159835815\n",
      "epoch:  9  total_correct:  1925  total_loss:  170.35107374191284\n",
      "epoch:  9  total_correct:  1987  total_loss:  175.18435287475586\n",
      "epoch:  9  total_correct:  2050  total_loss:  178.6883635520935\n",
      "epoch:  9  total_correct:  2067  total_loss:  180.66959977149963\n",
      "epoch:  10  total_correct:  60  total_loss:  8.576881408691406\n",
      "epoch:  10  total_correct:  122  total_loss:  12.874314308166504\n",
      "epoch:  10  total_correct:  185  total_loss:  17.440919399261475\n",
      "epoch:  10  total_correct:  248  total_loss:  20.552700519561768\n",
      "epoch:  10  total_correct:  307  total_loss:  30.195080280303955\n",
      "epoch:  10  total_correct:  367  total_loss:  38.96719980239868\n",
      "epoch:  10  total_correct:  428  total_loss:  45.83358907699585\n",
      "epoch:  10  total_correct:  490  total_loss:  51.5761604309082\n",
      "epoch:  10  total_correct:  551  total_loss:  57.9238862991333\n",
      "epoch:  10  total_correct:  615  total_loss:  61.42649865150452\n",
      "epoch:  10  total_correct:  677  total_loss:  68.74405550956726\n",
      "epoch:  10  total_correct:  740  total_loss:  72.40347385406494\n",
      "epoch:  10  total_correct:  802  total_loss:  77.28336429595947\n",
      "epoch:  10  total_correct:  866  total_loss:  80.28915548324585\n",
      "epoch:  10  total_correct:  928  total_loss:  84.8807806968689\n",
      "epoch:  10  total_correct:  990  total_loss:  91.50488090515137\n",
      "epoch:  10  total_correct:  1052  total_loss:  94.997487783432\n",
      "epoch:  10  total_correct:  1116  total_loss:  97.1003942489624\n",
      "epoch:  10  total_correct:  1179  total_loss:  102.47390079498291\n",
      "epoch:  10  total_correct:  1241  total_loss:  106.21198749542236\n",
      "epoch:  10  total_correct:  1303  total_loss:  111.8576340675354\n",
      "epoch:  10  total_correct:  1365  total_loss:  117.48010778427124\n",
      "epoch:  10  total_correct:  1428  total_loss:  122.86019659042358\n",
      "epoch:  10  total_correct:  1490  total_loss:  126.65972518920898\n",
      "epoch:  10  total_correct:  1552  total_loss:  134.54421949386597\n",
      "epoch:  10  total_correct:  1615  total_loss:  139.35296249389648\n",
      "epoch:  10  total_correct:  1679  total_loss:  141.08779191970825\n",
      "epoch:  10  total_correct:  1742  total_loss:  145.28266859054565\n",
      "epoch:  10  total_correct:  1803  total_loss:  152.66948461532593\n",
      "epoch:  10  total_correct:  1862  total_loss:  167.66166925430298\n",
      "epoch:  10  total_correct:  1921  total_loss:  175.62578630447388\n",
      "epoch:  10  total_correct:  1984  total_loss:  177.54837203025818\n",
      "epoch:  10  total_correct:  2047  total_loss:  180.1762251853943\n",
      "epoch:  10  total_correct:  2066  total_loss:  182.87155437469482\n",
      "epoch:  11  total_correct:  64  total_loss:  2.861943244934082\n",
      "epoch:  11  total_correct:  127  total_loss:  8.108444213867188\n",
      "epoch:  11  total_correct:  190  total_loss:  12.56235933303833\n",
      "epoch:  11  total_correct:  254  total_loss:  14.863329887390137\n",
      "epoch:  11  total_correct:  316  total_loss:  22.68160343170166\n",
      "epoch:  11  total_correct:  377  total_loss:  28.72295570373535\n",
      "epoch:  11  total_correct:  438  total_loss:  35.698410511016846\n",
      "epoch:  11  total_correct:  501  total_loss:  40.193443775177\n",
      "epoch:  11  total_correct:  564  total_loss:  43.465120792388916\n",
      "epoch:  11  total_correct:  627  total_loss:  49.41602945327759\n",
      "epoch:  11  total_correct:  691  total_loss:  52.084259033203125\n",
      "epoch:  11  total_correct:  754  total_loss:  55.48133373260498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  11  total_correct:  817  total_loss:  59.671372413635254\n",
      "epoch:  11  total_correct:  879  total_loss:  65.76745510101318\n",
      "epoch:  11  total_correct:  943  total_loss:  68.41450214385986\n",
      "epoch:  11  total_correct:  1007  total_loss:  72.47200965881348\n",
      "epoch:  11  total_correct:  1069  total_loss:  77.33892393112183\n",
      "epoch:  11  total_correct:  1131  total_loss:  82.83236074447632\n",
      "epoch:  11  total_correct:  1195  total_loss:  86.17287826538086\n",
      "epoch:  11  total_correct:  1257  total_loss:  90.54490566253662\n",
      "epoch:  11  total_correct:  1318  total_loss:  96.32688856124878\n",
      "epoch:  11  total_correct:  1382  total_loss:  98.78924798965454\n",
      "epoch:  11  total_correct:  1443  total_loss:  107.78089094161987\n",
      "epoch:  11  total_correct:  1506  total_loss:  112.52269506454468\n",
      "epoch:  11  total_correct:  1569  total_loss:  115.82120013237\n",
      "epoch:  11  total_correct:  1630  total_loss:  122.62456011772156\n",
      "epoch:  11  total_correct:  1690  total_loss:  129.52979350090027\n",
      "epoch:  11  total_correct:  1752  total_loss:  135.56813979148865\n",
      "epoch:  11  total_correct:  1813  total_loss:  143.19911170005798\n",
      "epoch:  11  total_correct:  1877  total_loss:  146.11513829231262\n",
      "epoch:  11  total_correct:  1939  total_loss:  151.0191342830658\n",
      "epoch:  11  total_correct:  2000  total_loss:  156.85322070121765\n",
      "epoch:  11  total_correct:  2061  total_loss:  165.18645358085632\n",
      "epoch:  11  total_correct:  2080  total_loss:  165.49051669239998\n",
      "epoch:  12  total_correct:  64  total_loss:  2.12744402885437\n",
      "epoch:  12  total_correct:  127  total_loss:  8.126171350479126\n",
      "epoch:  12  total_correct:  190  total_loss:  11.678928136825562\n",
      "epoch:  12  total_correct:  253  total_loss:  15.215788841247559\n",
      "epoch:  12  total_correct:  314  total_loss:  20.867223739624023\n",
      "epoch:  12  total_correct:  374  total_loss:  28.761343479156494\n",
      "epoch:  12  total_correct:  436  total_loss:  32.61316466331482\n",
      "epoch:  12  total_correct:  498  total_loss:  38.17998242378235\n",
      "epoch:  12  total_correct:  561  total_loss:  42.28894829750061\n",
      "epoch:  12  total_correct:  623  total_loss:  47.95356774330139\n",
      "epoch:  12  total_correct:  683  total_loss:  56.440046548843384\n",
      "epoch:  12  total_correct:  746  total_loss:  59.18735408782959\n",
      "epoch:  12  total_correct:  809  total_loss:  64.15679931640625\n",
      "epoch:  12  total_correct:  871  total_loss:  68.69680547714233\n",
      "epoch:  12  total_correct:  931  total_loss:  74.49279451370239\n",
      "epoch:  12  total_correct:  994  total_loss:  78.5449161529541\n",
      "epoch:  12  total_correct:  1057  total_loss:  82.33956265449524\n",
      "epoch:  12  total_correct:  1121  total_loss:  84.05061209201813\n",
      "epoch:  12  total_correct:  1185  total_loss:  86.24163544178009\n",
      "epoch:  12  total_correct:  1246  total_loss:  91.93605720996857\n",
      "epoch:  12  total_correct:  1310  total_loss:  93.17033505439758\n",
      "epoch:  12  total_correct:  1372  total_loss:  99.32595372200012\n",
      "epoch:  12  total_correct:  1435  total_loss:  102.25535106658936\n",
      "epoch:  12  total_correct:  1498  total_loss:  106.53531265258789\n",
      "epoch:  12  total_correct:  1560  total_loss:  110.27632761001587\n",
      "epoch:  12  total_correct:  1623  total_loss:  115.74780368804932\n",
      "epoch:  12  total_correct:  1687  total_loss:  117.99632263183594\n",
      "epoch:  12  total_correct:  1750  total_loss:  120.96834564208984\n",
      "epoch:  12  total_correct:  1810  total_loss:  133.25154495239258\n",
      "epoch:  12  total_correct:  1873  total_loss:  138.20400285720825\n",
      "epoch:  12  total_correct:  1935  total_loss:  143.27935361862183\n",
      "epoch:  12  total_correct:  1999  total_loss:  144.3590270280838\n",
      "epoch:  12  total_correct:  2063  total_loss:  147.15578138828278\n",
      "epoch:  12  total_correct:  2081  total_loss:  150.4839562177658\n",
      "epoch:  13  total_correct:  61  total_loss:  6.422072410583496\n",
      "epoch:  13  total_correct:  125  total_loss:  8.018820524215698\n",
      "epoch:  13  total_correct:  188  total_loss:  10.787096500396729\n",
      "epoch:  13  total_correct:  250  total_loss:  16.389726161956787\n",
      "epoch:  13  total_correct:  312  total_loss:  20.8368182182312\n",
      "epoch:  13  total_correct:  376  total_loss:  22.431588888168335\n",
      "epoch:  13  total_correct:  439  total_loss:  25.29278016090393\n",
      "epoch:  13  total_correct:  502  total_loss:  30.09895396232605\n",
      "epoch:  13  total_correct:  565  total_loss:  34.17242503166199\n",
      "epoch:  13  total_correct:  628  total_loss:  36.74564170837402\n",
      "epoch:  13  total_correct:  689  total_loss:  43.64467144012451\n",
      "epoch:  13  total_correct:  752  total_loss:  47.65697240829468\n",
      "epoch:  13  total_correct:  814  total_loss:  54.36592626571655\n",
      "epoch:  13  total_correct:  877  total_loss:  57.76580262184143\n",
      "epoch:  13  total_correct:  941  total_loss:  61.09057402610779\n",
      "epoch:  13  total_correct:  1004  total_loss:  66.10520529747009\n",
      "epoch:  13  total_correct:  1068  total_loss:  68.03807950019836\n",
      "epoch:  13  total_correct:  1131  total_loss:  73.27676320075989\n",
      "epoch:  13  total_correct:  1194  total_loss:  76.18178534507751\n",
      "epoch:  13  total_correct:  1253  total_loss:  83.26119208335876\n",
      "epoch:  13  total_correct:  1317  total_loss:  85.80753970146179\n",
      "epoch:  13  total_correct:  1379  total_loss:  93.18220973014832\n",
      "epoch:  13  total_correct:  1443  total_loss:  96.1907012462616\n",
      "epoch:  13  total_correct:  1507  total_loss:  98.83779740333557\n",
      "epoch:  13  total_correct:  1569  total_loss:  105.86474347114563\n",
      "epoch:  13  total_correct:  1631  total_loss:  109.74700713157654\n",
      "epoch:  13  total_correct:  1693  total_loss:  117.61646628379822\n",
      "epoch:  13  total_correct:  1755  total_loss:  121.57571792602539\n",
      "epoch:  13  total_correct:  1816  total_loss:  127.97156620025635\n",
      "epoch:  13  total_correct:  1879  total_loss:  131.32660126686096\n",
      "epoch:  13  total_correct:  1942  total_loss:  134.5244596004486\n",
      "epoch:  13  total_correct:  1998  total_loss:  152.2981355190277\n",
      "epoch:  13  total_correct:  2061  total_loss:  158.18944001197815\n",
      "epoch:  13  total_correct:  2079  total_loss:  163.71460509300232\n",
      "epoch:  14  total_correct:  62  total_loss:  3.8218939304351807\n",
      "epoch:  14  total_correct:  124  total_loss:  7.601500988006592\n",
      "epoch:  14  total_correct:  188  total_loss:  11.549362659454346\n",
      "epoch:  14  total_correct:  250  total_loss:  16.99592638015747\n",
      "epoch:  14  total_correct:  310  total_loss:  27.642488956451416\n",
      "epoch:  14  total_correct:  374  total_loss:  29.136685371398926\n",
      "epoch:  14  total_correct:  435  total_loss:  33.619601249694824\n",
      "epoch:  14  total_correct:  498  total_loss:  38.736440658569336\n",
      "epoch:  14  total_correct:  561  total_loss:  40.42488694190979\n",
      "epoch:  14  total_correct:  624  total_loss:  44.7911856174469\n",
      "epoch:  14  total_correct:  686  total_loss:  48.48776412010193\n",
      "epoch:  14  total_correct:  747  total_loss:  54.11748290061951\n",
      "epoch:  14  total_correct:  809  total_loss:  59.83142352104187\n",
      "epoch:  14  total_correct:  870  total_loss:  66.03903889656067\n",
      "epoch:  14  total_correct:  931  total_loss:  71.30776333808899\n",
      "epoch:  14  total_correct:  994  total_loss:  74.77854418754578\n",
      "epoch:  14  total_correct:  1057  total_loss:  76.90572452545166\n",
      "epoch:  14  total_correct:  1119  total_loss:  83.5494213104248\n",
      "epoch:  14  total_correct:  1179  total_loss:  91.16340970993042\n",
      "epoch:  14  total_correct:  1239  total_loss:  99.33566331863403\n",
      "epoch:  14  total_correct:  1302  total_loss:  102.62187886238098\n",
      "epoch:  14  total_correct:  1365  total_loss:  106.67509341239929\n",
      "epoch:  14  total_correct:  1428  total_loss:  110.12537026405334\n",
      "epoch:  14  total_correct:  1488  total_loss:  117.98562359809875\n",
      "epoch:  14  total_correct:  1550  total_loss:  122.13855528831482\n",
      "epoch:  14  total_correct:  1613  total_loss:  124.5647304058075\n",
      "epoch:  14  total_correct:  1677  total_loss:  125.37807929515839\n",
      "epoch:  14  total_correct:  1738  total_loss:  131.1101120710373\n",
      "epoch:  14  total_correct:  1798  total_loss:  139.4422129392624\n",
      "epoch:  14  total_correct:  1859  total_loss:  147.07893788814545\n",
      "epoch:  14  total_correct:  1920  total_loss:  159.46832692623138\n",
      "epoch:  14  total_correct:  1982  total_loss:  165.15008008480072\n",
      "epoch:  14  total_correct:  2046  total_loss:  167.00233280658722\n",
      "epoch:  14  total_correct:  2064  total_loss:  169.36335861682892\n",
      "epoch:  15  total_correct:  63  total_loss:  2.642704486846924\n",
      "epoch:  15  total_correct:  125  total_loss:  6.683272838592529\n",
      "epoch:  15  total_correct:  186  total_loss:  10.669780492782593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  15  total_correct:  250  total_loss:  13.618239164352417\n",
      "epoch:  15  total_correct:  312  total_loss:  18.35962986946106\n",
      "epoch:  15  total_correct:  374  total_loss:  22.515104055404663\n",
      "epoch:  15  total_correct:  437  total_loss:  26.29609227180481\n",
      "epoch:  15  total_correct:  500  total_loss:  31.803646326065063\n",
      "epoch:  15  total_correct:  564  total_loss:  33.75981783866882\n",
      "epoch:  15  total_correct:  628  total_loss:  35.908292055130005\n",
      "epoch:  15  total_correct:  690  total_loss:  41.57625603675842\n",
      "epoch:  15  total_correct:  753  total_loss:  45.70236849784851\n",
      "epoch:  15  total_correct:  816  total_loss:  48.055638551712036\n",
      "epoch:  15  total_correct:  880  total_loss:  50.840845823287964\n",
      "epoch:  15  total_correct:  942  total_loss:  53.98202919960022\n",
      "epoch:  15  total_correct:  1006  total_loss:  56.815338373184204\n",
      "epoch:  15  total_correct:  1070  total_loss:  58.66062569618225\n",
      "epoch:  15  total_correct:  1130  total_loss:  65.31295990943909\n",
      "epoch:  15  total_correct:  1190  total_loss:  77.19199204444885\n",
      "epoch:  15  total_correct:  1253  total_loss:  80.46324419975281\n",
      "epoch:  15  total_correct:  1313  total_loss:  88.72904372215271\n",
      "epoch:  15  total_correct:  1377  total_loss:  91.05865287780762\n",
      "epoch:  15  total_correct:  1438  total_loss:  95.75106525421143\n",
      "epoch:  15  total_correct:  1501  total_loss:  99.27199029922485\n",
      "epoch:  15  total_correct:  1564  total_loss:  101.0127637386322\n",
      "epoch:  15  total_correct:  1628  total_loss:  103.15559005737305\n",
      "epoch:  15  total_correct:  1692  total_loss:  105.52080059051514\n",
      "epoch:  15  total_correct:  1756  total_loss:  106.25178492069244\n",
      "epoch:  15  total_correct:  1818  total_loss:  109.70137083530426\n",
      "epoch:  15  total_correct:  1880  total_loss:  115.81018793582916\n",
      "epoch:  15  total_correct:  1944  total_loss:  116.87215435504913\n",
      "epoch:  15  total_correct:  2006  total_loss:  122.12120831012726\n",
      "epoch:  15  total_correct:  2067  total_loss:  127.88206970691681\n",
      "epoch:  15  total_correct:  2084  total_loss:  131.93457520008087\n",
      "epoch:  16  total_correct:  61  total_loss:  5.8547282218933105\n",
      "epoch:  16  total_correct:  124  total_loss:  9.347739219665527\n",
      "epoch:  16  total_correct:  183  total_loss:  17.071255207061768\n",
      "epoch:  16  total_correct:  247  total_loss:  18.304550170898438\n",
      "epoch:  16  total_correct:  310  total_loss:  23.00718879699707\n",
      "epoch:  16  total_correct:  372  total_loss:  28.245708465576172\n",
      "epoch:  16  total_correct:  436  total_loss:  30.489593982696533\n",
      "epoch:  16  total_correct:  500  total_loss:  32.30981492996216\n",
      "epoch:  16  total_correct:  564  total_loss:  33.158169865608215\n",
      "epoch:  16  total_correct:  626  total_loss:  36.974056363105774\n",
      "epoch:  16  total_correct:  689  total_loss:  39.03239381313324\n",
      "epoch:  16  total_correct:  750  total_loss:  45.51645076274872\n",
      "epoch:  16  total_correct:  814  total_loss:  47.466808915138245\n",
      "epoch:  16  total_correct:  877  total_loss:  51.84876024723053\n",
      "epoch:  16  total_correct:  940  total_loss:  53.41706895828247\n",
      "epoch:  16  total_correct:  1001  total_loss:  60.24706554412842\n",
      "epoch:  16  total_correct:  1065  total_loss:  61.28305625915527\n",
      "epoch:  16  total_correct:  1124  total_loss:  71.52113056182861\n",
      "epoch:  16  total_correct:  1188  total_loss:  72.70464527606964\n",
      "epoch:  16  total_correct:  1252  total_loss:  75.49440491199493\n",
      "epoch:  16  total_correct:  1315  total_loss:  78.94835102558136\n",
      "epoch:  16  total_correct:  1377  total_loss:  84.67662060260773\n",
      "epoch:  16  total_correct:  1436  total_loss:  95.88136684894562\n",
      "epoch:  16  total_correct:  1500  total_loss:  97.88960325717926\n",
      "epoch:  16  total_correct:  1563  total_loss:  99.45341360569\n",
      "epoch:  16  total_correct:  1626  total_loss:  102.07051575183868\n",
      "epoch:  16  total_correct:  1688  total_loss:  105.70687973499298\n",
      "epoch:  16  total_correct:  1751  total_loss:  109.95421659946442\n",
      "epoch:  16  total_correct:  1813  total_loss:  112.75790107250214\n",
      "epoch:  16  total_correct:  1875  total_loss:  115.90593206882477\n",
      "epoch:  16  total_correct:  1937  total_loss:  119.7105747461319\n",
      "epoch:  16  total_correct:  2000  total_loss:  121.77979052066803\n",
      "epoch:  16  total_correct:  2062  total_loss:  125.73441088199615\n",
      "epoch:  16  total_correct:  2080  total_loss:  128.80102598667145\n",
      "epoch:  17  total_correct:  63  total_loss:  3.984380006790161\n",
      "epoch:  17  total_correct:  127  total_loss:  4.881940126419067\n",
      "epoch:  17  total_correct:  190  total_loss:  8.603987693786621\n",
      "epoch:  17  total_correct:  253  total_loss:  10.764108896255493\n",
      "epoch:  17  total_correct:  315  total_loss:  15.215180158615112\n",
      "epoch:  17  total_correct:  375  total_loss:  22.160635709762573\n",
      "epoch:  17  total_correct:  437  total_loss:  27.092694997787476\n",
      "epoch:  17  total_correct:  500  total_loss:  28.842840909957886\n",
      "epoch:  17  total_correct:  562  total_loss:  33.82154154777527\n",
      "epoch:  17  total_correct:  623  total_loss:  43.39361834526062\n",
      "epoch:  17  total_correct:  687  total_loss:  45.20875525474548\n",
      "epoch:  17  total_correct:  751  total_loss:  46.550469636917114\n",
      "epoch:  17  total_correct:  811  total_loss:  55.20063328742981\n",
      "epoch:  17  total_correct:  872  total_loss:  61.73483490943909\n",
      "epoch:  17  total_correct:  934  total_loss:  65.73951935768127\n",
      "epoch:  17  total_correct:  997  total_loss:  69.77155041694641\n",
      "epoch:  17  total_correct:  1060  total_loss:  72.65240144729614\n",
      "epoch:  17  total_correct:  1120  total_loss:  79.31031656265259\n",
      "epoch:  17  total_correct:  1183  total_loss:  81.14075922966003\n",
      "epoch:  17  total_correct:  1247  total_loss:  82.78673160076141\n",
      "epoch:  17  total_correct:  1310  total_loss:  85.74378907680511\n",
      "epoch:  17  total_correct:  1372  total_loss:  92.3250116109848\n",
      "epoch:  17  total_correct:  1436  total_loss:  93.25701361894608\n",
      "epoch:  17  total_correct:  1498  total_loss:  97.15536719560623\n",
      "epoch:  17  total_correct:  1560  total_loss:  101.99959832429886\n",
      "epoch:  17  total_correct:  1623  total_loss:  105.82742887735367\n",
      "epoch:  17  total_correct:  1684  total_loss:  110.9805617928505\n",
      "epoch:  17  total_correct:  1747  total_loss:  112.2514129281044\n",
      "epoch:  17  total_correct:  1810  total_loss:  114.81079059839249\n",
      "epoch:  17  total_correct:  1873  total_loss:  117.94569355249405\n",
      "epoch:  17  total_correct:  1937  total_loss:  118.72401028871536\n",
      "epoch:  17  total_correct:  1999  total_loss:  123.1090515255928\n",
      "epoch:  17  total_correct:  2057  total_loss:  138.71979600191116\n",
      "epoch:  17  total_correct:  2073  total_loss:  150.73501378297806\n",
      "epoch:  18  total_correct:  61  total_loss:  11.952191352844238\n",
      "epoch:  18  total_correct:  124  total_loss:  15.116721630096436\n",
      "epoch:  18  total_correct:  187  total_loss:  17.48603391647339\n",
      "epoch:  18  total_correct:  249  total_loss:  21.546509265899658\n",
      "epoch:  18  total_correct:  310  total_loss:  26.580488681793213\n",
      "epoch:  18  total_correct:  373  total_loss:  29.446312427520752\n",
      "epoch:  18  total_correct:  436  total_loss:  31.242404222488403\n",
      "epoch:  18  total_correct:  498  total_loss:  34.50566244125366\n",
      "epoch:  18  total_correct:  560  total_loss:  36.697293281555176\n",
      "epoch:  18  total_correct:  623  total_loss:  40.53599143028259\n",
      "epoch:  18  total_correct:  684  total_loss:  47.04202342033386\n",
      "epoch:  18  total_correct:  748  total_loss:  49.44226884841919\n",
      "epoch:  18  total_correct:  810  total_loss:  53.03160071372986\n",
      "epoch:  18  total_correct:  872  total_loss:  61.63009238243103\n",
      "epoch:  18  total_correct:  932  total_loss:  72.8804223537445\n",
      "epoch:  18  total_correct:  994  total_loss:  81.76415610313416\n",
      "epoch:  18  total_correct:  1056  total_loss:  88.77498888969421\n",
      "epoch:  18  total_correct:  1119  total_loss:  91.44164633750916\n",
      "epoch:  18  total_correct:  1183  total_loss:  92.73263740539551\n",
      "epoch:  18  total_correct:  1245  total_loss:  99.72496938705444\n",
      "epoch:  18  total_correct:  1308  total_loss:  102.81187200546265\n",
      "epoch:  18  total_correct:  1372  total_loss:  105.00741958618164\n",
      "epoch:  18  total_correct:  1434  total_loss:  109.53803873062134\n",
      "epoch:  18  total_correct:  1497  total_loss:  113.78488683700562\n",
      "epoch:  18  total_correct:  1560  total_loss:  118.58601999282837\n",
      "epoch:  18  total_correct:  1623  total_loss:  123.24191188812256\n",
      "epoch:  18  total_correct:  1687  total_loss:  125.07065796852112\n",
      "epoch:  18  total_correct:  1751  total_loss:  127.8162853717804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  18  total_correct:  1814  total_loss:  130.7335329055786\n",
      "epoch:  18  total_correct:  1876  total_loss:  138.02287578582764\n",
      "epoch:  18  total_correct:  1939  total_loss:  141.4637634754181\n",
      "epoch:  18  total_correct:  2002  total_loss:  147.02098441123962\n",
      "epoch:  18  total_correct:  2066  total_loss:  148.70085334777832\n",
      "epoch:  18  total_correct:  2084  total_loss:  150.34628438949585\n",
      "epoch:  19  total_correct:  62  total_loss:  5.729355812072754\n",
      "epoch:  19  total_correct:  126  total_loss:  8.624703884124756\n",
      "epoch:  19  total_correct:  188  total_loss:  13.53842306137085\n",
      "epoch:  19  total_correct:  249  total_loss:  20.395144939422607\n",
      "epoch:  19  total_correct:  312  total_loss:  24.776050090789795\n",
      "epoch:  19  total_correct:  376  total_loss:  26.314030170440674\n",
      "epoch:  19  total_correct:  440  total_loss:  27.94584321975708\n",
      "epoch:  19  total_correct:  503  total_loss:  31.652157306671143\n",
      "epoch:  19  total_correct:  567  total_loss:  33.89088416099548\n",
      "epoch:  19  total_correct:  631  total_loss:  36.795007944107056\n",
      "epoch:  19  total_correct:  693  total_loss:  40.92019724845886\n",
      "epoch:  19  total_correct:  755  total_loss:  46.57364296913147\n",
      "epoch:  19  total_correct:  818  total_loss:  51.57053732872009\n",
      "epoch:  19  total_correct:  882  total_loss:  54.150151014328\n",
      "epoch:  19  total_correct:  946  total_loss:  56.26442909240723\n",
      "epoch:  19  total_correct:  1007  total_loss:  61.25665283203125\n",
      "epoch:  19  total_correct:  1070  total_loss:  69.61057186126709\n",
      "epoch:  19  total_correct:  1131  total_loss:  75.17596292495728\n",
      "epoch:  19  total_correct:  1195  total_loss:  75.74876695871353\n",
      "epoch:  19  total_correct:  1258  total_loss:  78.31036001443863\n",
      "epoch:  19  total_correct:  1322  total_loss:  79.26388281583786\n",
      "epoch:  19  total_correct:  1382  total_loss:  86.24692744016647\n",
      "epoch:  19  total_correct:  1444  total_loss:  90.28009527921677\n",
      "epoch:  19  total_correct:  1506  total_loss:  94.45359963178635\n",
      "epoch:  19  total_correct:  1569  total_loss:  97.75451344251633\n",
      "epoch:  19  total_correct:  1633  total_loss:  98.67208451032639\n",
      "epoch:  19  total_correct:  1695  total_loss:  108.10669201612473\n",
      "epoch:  19  total_correct:  1755  total_loss:  115.29932659864426\n",
      "epoch:  19  total_correct:  1817  total_loss:  119.84830921888351\n",
      "epoch:  19  total_correct:  1879  total_loss:  123.39855688810349\n",
      "epoch:  19  total_correct:  1943  total_loss:  124.80114072561264\n",
      "epoch:  19  total_correct:  2004  total_loss:  129.76405185461044\n",
      "epoch:  19  total_correct:  2065  total_loss:  139.06066554784775\n",
      "epoch:  19  total_correct:  2084  total_loss:  139.4884471297264\n",
      "epoch:  20  total_correct:  63  total_loss:  3.3404836654663086\n",
      "epoch:  20  total_correct:  126  total_loss:  9.49513292312622\n",
      "epoch:  20  total_correct:  190  total_loss:  11.212190866470337\n",
      "epoch:  20  total_correct:  252  total_loss:  14.363239526748657\n",
      "epoch:  20  total_correct:  313  total_loss:  19.485039949417114\n",
      "epoch:  20  total_correct:  374  total_loss:  25.457165956497192\n",
      "epoch:  20  total_correct:  435  total_loss:  29.760016202926636\n",
      "epoch:  20  total_correct:  498  total_loss:  32.586989641189575\n",
      "epoch:  20  total_correct:  559  total_loss:  39.23563885688782\n",
      "epoch:  20  total_correct:  621  total_loss:  43.27869009971619\n",
      "epoch:  20  total_correct:  685  total_loss:  43.900575280189514\n",
      "epoch:  20  total_correct:  746  total_loss:  50.193230748176575\n",
      "epoch:  20  total_correct:  810  total_loss:  51.87925899028778\n",
      "epoch:  20  total_correct:  873  total_loss:  54.77329862117767\n",
      "epoch:  20  total_correct:  936  total_loss:  59.49776875972748\n",
      "epoch:  20  total_correct:  998  total_loss:  64.25877130031586\n",
      "epoch:  20  total_correct:  1060  total_loss:  67.72990691661835\n",
      "epoch:  20  total_correct:  1123  total_loss:  70.89296329021454\n",
      "epoch:  20  total_correct:  1186  total_loss:  72.24039900302887\n",
      "epoch:  20  total_correct:  1250  total_loss:  74.81760823726654\n",
      "epoch:  20  total_correct:  1311  total_loss:  80.35991942882538\n",
      "epoch:  20  total_correct:  1374  total_loss:  84.67010009288788\n",
      "epoch:  20  total_correct:  1436  total_loss:  89.66163337230682\n",
      "epoch:  20  total_correct:  1499  total_loss:  93.49892556667328\n",
      "epoch:  20  total_correct:  1562  total_loss:  95.85559976100922\n",
      "epoch:  20  total_correct:  1626  total_loss:  96.72499811649323\n",
      "epoch:  20  total_correct:  1688  total_loss:  100.36841833591461\n",
      "epoch:  20  total_correct:  1751  total_loss:  102.79998743534088\n",
      "epoch:  20  total_correct:  1815  total_loss:  104.21371579170227\n",
      "epoch:  20  total_correct:  1879  total_loss:  105.06285881996155\n",
      "epoch:  20  total_correct:  1943  total_loss:  106.89130854606628\n",
      "epoch:  20  total_correct:  2005  total_loss:  110.73813462257385\n",
      "epoch:  20  total_correct:  2068  total_loss:  114.387286901474\n",
      "epoch:  20  total_correct:  2087  total_loss:  114.50390004366636\n",
      "epoch:  21  total_correct:  64  total_loss:  0.8205081224441528\n",
      "epoch:  21  total_correct:  127  total_loss:  3.914075493812561\n",
      "epoch:  21  total_correct:  189  total_loss:  7.155954003334045\n",
      "epoch:  21  total_correct:  252  total_loss:  10.104984641075134\n",
      "epoch:  21  total_correct:  316  total_loss:  11.955775380134583\n",
      "epoch:  21  total_correct:  380  total_loss:  13.302465796470642\n",
      "epoch:  21  total_correct:  443  total_loss:  17.28949773311615\n",
      "epoch:  21  total_correct:  506  total_loss:  21.85714089870453\n",
      "epoch:  21  total_correct:  570  total_loss:  23.556660890579224\n",
      "epoch:  21  total_correct:  633  total_loss:  28.64116358757019\n",
      "epoch:  21  total_correct:  696  total_loss:  31.398128032684326\n",
      "epoch:  21  total_correct:  760  total_loss:  33.0086727142334\n",
      "epoch:  21  total_correct:  822  total_loss:  36.627593994140625\n",
      "epoch:  21  total_correct:  884  total_loss:  41.197747230529785\n",
      "epoch:  21  total_correct:  948  total_loss:  42.48719370365143\n",
      "epoch:  21  total_correct:  1012  total_loss:  44.247663378715515\n",
      "epoch:  21  total_correct:  1074  total_loss:  48.48877513408661\n",
      "epoch:  21  total_correct:  1136  total_loss:  53.059409976005554\n",
      "epoch:  21  total_correct:  1200  total_loss:  55.66601264476776\n",
      "epoch:  21  total_correct:  1264  total_loss:  57.86033260822296\n",
      "epoch:  21  total_correct:  1328  total_loss:  59.81515312194824\n",
      "epoch:  21  total_correct:  1392  total_loss:  61.49401021003723\n",
      "epoch:  21  total_correct:  1454  total_loss:  68.65598511695862\n",
      "epoch:  21  total_correct:  1517  total_loss:  71.41851162910461\n",
      "epoch:  21  total_correct:  1580  total_loss:  74.01784348487854\n",
      "epoch:  21  total_correct:  1641  total_loss:  82.86281037330627\n",
      "epoch:  21  total_correct:  1704  total_loss:  87.61509680747986\n",
      "epoch:  21  total_correct:  1766  total_loss:  90.68373894691467\n",
      "epoch:  21  total_correct:  1830  total_loss:  91.85729825496674\n",
      "epoch:  21  total_correct:  1892  total_loss:  96.47510945796967\n",
      "epoch:  21  total_correct:  1954  total_loss:  101.31705176830292\n",
      "epoch:  21  total_correct:  2015  total_loss:  105.72949588298798\n",
      "epoch:  21  total_correct:  2079  total_loss:  107.17658185958862\n",
      "epoch:  21  total_correct:  2098  total_loss:  107.56233832240105\n",
      "epoch:  22  total_correct:  64  total_loss:  0.9052168130874634\n",
      "epoch:  22  total_correct:  128  total_loss:  1.809963345527649\n",
      "epoch:  22  total_correct:  192  total_loss:  2.935140609741211\n",
      "epoch:  22  total_correct:  255  total_loss:  5.863448619842529\n",
      "epoch:  22  total_correct:  319  total_loss:  8.21492886543274\n",
      "epoch:  22  total_correct:  382  total_loss:  10.456162452697754\n",
      "epoch:  22  total_correct:  446  total_loss:  12.315702080726624\n",
      "epoch:  22  total_correct:  509  total_loss:  14.787256121635437\n",
      "epoch:  22  total_correct:  573  total_loss:  15.664364337921143\n",
      "epoch:  22  total_correct:  636  total_loss:  18.52620267868042\n",
      "epoch:  22  total_correct:  699  total_loss:  21.553560972213745\n",
      "epoch:  22  total_correct:  759  total_loss:  27.408334493637085\n",
      "epoch:  22  total_correct:  822  total_loss:  31.72589945793152\n",
      "epoch:  22  total_correct:  884  total_loss:  35.803194761276245\n",
      "epoch:  22  total_correct:  948  total_loss:  37.37568998336792\n",
      "epoch:  22  total_correct:  1009  total_loss:  43.70250940322876\n",
      "epoch:  22  total_correct:  1072  total_loss:  45.27972185611725\n",
      "epoch:  22  total_correct:  1134  total_loss:  48.862069964408875\n",
      "epoch:  22  total_correct:  1195  total_loss:  56.33346784114838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  22  total_correct:  1259  total_loss:  59.18312609195709\n",
      "epoch:  22  total_correct:  1322  total_loss:  60.77596986293793\n",
      "epoch:  22  total_correct:  1383  total_loss:  66.71681678295135\n",
      "epoch:  22  total_correct:  1446  total_loss:  70.94444072246552\n",
      "epoch:  22  total_correct:  1509  total_loss:  75.96457612514496\n",
      "epoch:  22  total_correct:  1572  total_loss:  79.06479489803314\n",
      "epoch:  22  total_correct:  1632  total_loss:  86.83328187465668\n",
      "epoch:  22  total_correct:  1694  total_loss:  96.16174447536469\n",
      "epoch:  22  total_correct:  1757  total_loss:  97.85346758365631\n",
      "epoch:  22  total_correct:  1820  total_loss:  100.05451786518097\n",
      "epoch:  22  total_correct:  1883  total_loss:  105.79401648044586\n",
      "epoch:  22  total_correct:  1947  total_loss:  107.6103367805481\n",
      "epoch:  22  total_correct:  2010  total_loss:  111.19250988960266\n",
      "epoch:  22  total_correct:  2073  total_loss:  115.01529955863953\n",
      "epoch:  22  total_correct:  2092  total_loss:  115.29491311311722\n",
      "train accuracy:  0.9613970588235294\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'focal_loss_multilabel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-0e128ec09a52>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mtotal_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint_train_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mtotal_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mprint_validation_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mtotal_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5b58c94909f2>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(resnet50, device, train_loader, n, tb, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#                 loss = F.cross_entropy(preds,labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#if you want to calculate it using the focal loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfocal_loss_multilabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#if you want to calculate it using the normal cross entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'focal_loss_multilabel' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
